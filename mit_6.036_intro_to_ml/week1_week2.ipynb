{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a68e0db-206c-4209-9491-3c4790480483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19069de6-8c27-430e-bb1f-8a6aeb34e83c",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cabd703-a868-46f5-86ab-29bba88768c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv(value_list):\n",
    "    return np.array([value_list])\n",
    "\n",
    "def cv(value_list):\n",
    "    return np.array([value_list]).T\n",
    "\n",
    "\n",
    "def length(col_v):\n",
    "    return ((col_v.T@col_v)**.5)[0,0]\n",
    "\n",
    "def normalize(col_v):\n",
    "    return col_v/length(col_v)\n",
    "\n",
    "def signed_dist(x, th, th0):\n",
    "    x = np.array(x)\n",
    "    th = np.array(th)\n",
    "    return (x.T@th + th0) / length(th)\n",
    "\n",
    "def positive(x, th, th0):\n",
    "    return np.sign(signed_dist(x, th, th0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cafe8a47-e213-4c7e-a32d-2503d0046c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  1,  2,  1,  2],\n",
       "        [ 2,  3,  1, -1, -1]]),\n",
       " array([[-1, -1,  1,  1,  1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.transpose(np.array([[1, 2], [1, 3], [2, 1], [1, -1], [2, -1]]))\n",
    "labels = rv([-1, -1, +1, +1, +1])\n",
    "data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428b7980-b5ac-4fdf-a356-975646783044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.]]),\n",
       " array([[False, False,  True, False, False]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def point_sign(p, axis):\n",
    "    return np.sign(signed_dist(p, th, th0))\n",
    "th = np.array([[1], [1]])\n",
    "th0 = -2\n",
    "B  = np.apply_over_axes(point_sign, data, axes=1)\n",
    "A = B.T == labels\n",
    "B,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0904d9a1-90b2-40f9-ab89-1a248c50dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5\n",
    "\n",
    "def length(col_v):\n",
    "    return ((col_v.T@col_v)**.5)[0,0]\n",
    "\n",
    "\n",
    "def signed_dist(x, th, th0):\n",
    "    x = np.array(x)\n",
    "    th = np.array(th)\n",
    "    return (x.T@th + th0) / length(th)\n",
    "\n",
    "def score(data, labels, th, th0):\n",
    "    def point_sign(p, axis):\n",
    "        return np.sign(signed_dist(p, th, th0))\n",
    "    return np.sum(np.apply_over_axes(point_sign, data, axes=1).T == labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8e9b88a-9e4b-4296-9e39-876473464f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def length(col_v):\n",
    "    return ((col_v.T@col_v)**.5)[0,0]\n",
    "\n",
    "def signed_dist(x, th, th0):\n",
    "    x = np.array(x)\n",
    "    th = np.array(th)\n",
    "    return (x.T@th + th0) / length(th)\n",
    "\n",
    "def score(data, labels, th, th0):\n",
    "    def point_sign(p, axis):\n",
    "        return np.sign(signed_dist(p, th, th0))\n",
    "    return np.sum(np.apply_over_axes(point_sign, data, axes=1).T == labels)\n",
    "\n",
    "\n",
    "def best_separator(data, labels, ths, th0s):\n",
    "    mysum = np.sum(np.sign(ths.T @ data + th0s.T) == labels, axis=1)\n",
    "    i = np.argmax(mysum)\n",
    "    return ths[:,i:], th0s[:,i:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e35a5fa0-0030-4e85-b04c-6d4d09f01df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.32548657],\n",
       "        [-0.83807759]]),\n",
       " array([[0.74308104]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([\n",
    "    [1,  1,  2,  1,  2],\n",
    "    [2,  3,  1, -1, -1]\n",
    "])\n",
    "labels = np.array([[-1, -1,  1,  1,  1]])\n",
    "ths = np.array([\n",
    "    [0.98645534, -0.02061321, -0.30421124, -0.62960452,  0.61617711, 0.17344772, -0.21804797,  0.26093651,  0.47179699,  0.32548657],\n",
    "    [0.87953335,  0.39605039, -0.1105264 ,  0.71212565, -0.39195678, 0.00999743, -0.88220145, -0.73546501, -0.7769778 , -0.83807759]\n",
    "])\n",
    "th0s = np.array([\n",
    "    [0.65043158,  0.61626967,  0.84632592, -0.43047804, -0.91768579, -0.3214327 ,  0.0682113 , -0.20678004, -0.33963784,  0.74308104]\n",
    "])\n",
    "\n",
    "mysum = np.sum(np.sign(ths.T @ data + th0s.T) == labels, axis=1)\n",
    "i = np.argmax(mysum)\n",
    "i, mysum, ths.T[i]\n",
    "best_separator(data, labels, ths, th0s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfec55-526d-4d0d-af28-fd62d06da023",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d49da291-3c9b-42f2-bc01-b1c5469969ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15],\n",
       "       [-7],\n",
       "       [ 1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = np.array([[1, -1, 2, -3]])\n",
    "\n",
    "X = np.array([\n",
    "    [1, -1, 2, -3],\n",
    "    [1, 2, 3, 4],\n",
    "    [-1, -1, -1, -1],\n",
    "    [1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "X@th.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ed1c4-83bf-4dc1-a80d-eda75847d016",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "### 1) \n",
    "\n",
    "> A) Percy Eptron suggests reusing the training data to assess hhh:\n",
    "> eval_classifier(h, D_train)\n",
    "\n",
    "> Explain why Percy's strategy might not be so good.\n",
    "\n",
    "Because the training data was used to find the hypothesis, the `h` so it will always return perferct score for D_train.\n",
    "\n",
    "> B) Now write down a better approach for evaluating h, which may use h, G\\mathcal{G}G, and Dtrain\\mathcal{D}_{\\it train}Dtrain​, and computes a score for hhh. The syntax is not important, but do write something down. What does this score measure and what is the range of possible outputs?\n",
    "\n",
    "D_test = G()  # return new data set\n",
    "test_score = eval_classifier(h, D_test) # this measures how h good on this unseen set of data that was pulled independently from D_train from the dataset. So it's elements from n+1 to n+n', where n is length of D_train and n' is length of D_test.\n",
    "\n",
    "> C) Explain why your method might be more desirable than Percy's. What problem does it fix?\n",
    "\n",
    "Because this points h wasn't trained at. It fixes the problem of always predicting 0 error rate for D_train.\n",
    "\n",
    "> D) How would your method from B score the classifier hhh, if Dtest\\mathcal{D}_{\\it test}Dtest​ came from a different distribution than G\\mathcal{G}G, but Dtrain\\mathcal{D}_{\\it train}Dtrain​ was unchanged?\n",
    "\n",
    "Then the func from B would give irrelevant, meaningless score because h was trained on a different set.\n",
    "\n",
    "### 2)\n",
    "\n",
    "A) \n",
    "\n",
    "> Would running the learning algorithm LLL on two different training datasets Dtrain1\\mathcal{D}_{\\it train_1}Dtrain1​​ and Dtrain2\\mathcal{D}_{\\it train_2}Dtrain2​​ produce the same classifier? In other words, would h1h_1h1​ = L(Dtrain1)L(\\mathcal{D}_{\\it train_1})L(Dtrain1​​) be the same classifier as h2h_2h2​ = L(Dtrain2)L(\\mathcal{D}_{\\it train_2})L(Dtrain2​​)? What if those training datasets were pulled from the same distribution? \n",
    "\n",
    "No, it is unlikely that it will produce the same classifier because L might consider those points in different order or even randomly choose `h` hypothesis.\n",
    "Even if those where the same distribution `L` will very likely give different `h`s.\n",
    "\n",
    "> you'll need to assess the learning algorithm's performance in the context of a particular data source.\n",
    "\n",
    "That's interesting. No free lunch theorem (NFL) states that there are no prediction strategy that scores better than any other strategy if they are taken for all possible problems.\n",
    "\n",
    "> What is the difference between a classifier and a learning algorithm? \n",
    "\n",
    "Classifier is a hypothesis function that is used to predict labels (classes). A learning algorith is a function that produces a model or generalization of a problem.\n",
    "\n",
    "B) \n",
    "\n",
    "> What are GGG and nnn in the code above?\n",
    "\n",
    "G is a generator, i.e. an iterator over the dataset that produces a matrix with n points and n labels.\n",
    "n is the number of samples to pull from G.\n",
    "\n",
    "> Explain why Linnea's strategy might not be so good.\n",
    "\n",
    "- Performance problem. And possible out of data. It pulls the same number of points to eval the algorithm as it did to train it. It is unlikely it needs the same number of points to get the score.\n",
    "- It doesn't provide hyperparameter to L if it requires it as in our lectures the Perceptron requires T hyperparameter.\n",
    "- It might pull a set for test that is close to the train set, i.e. they are ordered. Not representful.\n",
    "\n",
    "C)\n",
    "\n",
    "> Is Linnea's strategy good now? Explain why or why not. \n",
    "\n",
    "- Better as it is now might pull substantial amount of points to detect bad hypothesis. \n",
    "- Again performance and out of data problems. It needs 11 times n data points\n",
    "- Again bad representation if points ordered.\n",
    "\n",
    "D)\n",
    "\n",
    "```\n",
    "def better_eval_learning_alg(L, G, n):\n",
    "    pulled_set = G(n*2)  # Or randomly from all data in source without considering n.\n",
    "    train, test = randomly divide pulled_set into two sets with 0.8-0.2 ratio or other.\n",
    "    h = L(train.X, train.Y)\n",
    "    score = eval_classifier(h, test)\n",
    "    return score\n",
    "```\n",
    "    \n",
    "> E) Explain why your method might be more desirable than Linnea's.\n",
    "\n",
    "- Now avoiding the ordered points issue.\n",
    "- Avoiding the performance issue.\n",
    "- Avoiding out of data if n times 10 leads to it.\n",
    "- Evaluating only once.\n",
    "\n",
    "\n",
    "### 3)\n",
    "\n",
    "> A) In the last section, you thought about how to evaluate a learning algorithm. Now that you are given only 100 labeled data points in total, how would you evaluate a learning algorithm? Specifically, how would you implement better_eval_learning_alg from 2C) without G\\mathcal{G}G but instead with your 100 labeled data? \n",
    "\n",
    "Randomly divide those 100 points into two sets for training and for testing. Perhaps 0.9 ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e809821c-ac96-4abe-a0b7-8569cc5d0572",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116007ce-bb9b-46d8-a799-f6c199180968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2, 0], -5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Dual View\n",
    "\n",
    "theta = [\n",
    "    -3*2+4+2-2*1,\n",
    "    2*2-4+2-2]\n",
    "theta_0 = 2-4-2-1\n",
    "theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df327a79-4e59-4726-b770-34e8a66ccd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654be98b-d072-4ab7-a47a-edc79bfb0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [.00001, .0001, .001, .01, .1, .2, .5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
